{"componentChunkName":"component---src-templates-blog-post-js","path":"/node-log-rotate/","webpackCompilationHash":"b0082026f0d2e3ac3c54","result":{"data":{"site":{"siteMetadata":{"title":"云音乐大前端专栏","author":"云音乐大前端团队","siteUrl":"https://musicfe.dev"}},"markdownRemark":{"id":"6308c41a-e322-5e4a-9352-516958f249c8","excerpt":"header.png 图片来源：https://medium.com/encored-technologies-engineering-data-science 本文作者：夏银竹 引子 2019 年初的时候，我们业务组上线了一个新的 Node.js 应用，主要提供C端的 API…","html":"<p><img src=\"https://p1.music.126.net/2cl1EHjmsCqVSx3LGcbdgA==/109951164836572898.png\" alt=\"header.png\"></p>\n<blockquote>\n<p>图片来源：<a href=\"https://medium.com/encored-technologies-engineering-data-science\">https://medium.com/encored-technologies-engineering-data-science</a></p>\n</blockquote>\n<blockquote>\n<p>本文作者：<a href=\"https://github.com/EllieSummer\">夏银竹</a></p>\n</blockquote>\n<h2>引子</h2>\n<p>2019 年初的时候，我们业务组上线了一个新的 Node.js 应用，主要提供C端的 API 服务。 随着应用流量的逐渐增加，线上监控平台会偶发性报警，提示磁盘 disk_io 平均等待时间超出 1000ms，随后观察发现磁盘 IO 每秒写字节量突然飙高，但很快又下降。</p>\n<p><img src=\"https://p1.music.126.net/9McmLeu_TIjzDotdgspHBw==/109951164021826212.png\"></p>\n<p>具体的监控图表如上所示，线上 Node.js 应用向磁盘写入数据的唯一场景就是打印日志，通过iotop、ps 等命令也验证了该异常正是由于 Node.js 的日志切割进程导致的。</p>\n<p>可是为什么日志切割会引起这么诡异的 IO 问题呢？在揭开谜底之前，我们先聊一聊 Node.js 应用日志切割的原理。</p>\n<h2>日志切割原理</h2>\n<h3>为什么需要日志切割</h3>\n<p>日志打印是 Node.js 工程服务化过程中一个必不可少的环节。日志文件中包含了系统运行过程中的关键信息，常用于故障诊断和系统的性能分析。</p>\n<p>在日志打印的过程中通常会遇到两个问题： </p>\n<ol>\n<li>随着时间的积累，日志文件大小会逐渐增长，系统磁盘的空间会被消耗得越来越多，将面临着日志写入失败、服务异常的问题。</li>\n<li>服务的日志默认存储在单个文件中，自定义查看历史某个时间段的日志将会变得比较困难，期望日志文件能够按照一定的规则切割，以便于排序和筛选。</li>\n</ol>\n<p>所以，在生产环境中通常会采用日志切割来解决上述的问题。日志切割可以限制日志文件个数， 删除旧的日志文件，并创建新的日志文件，起到“转储作用”。</p>\n<h3>实现机制</h3>\n<p>不同的日志切割组件会采用不同的实现机制，常见的有以下两种： </p>\n<ul>\n<li>\n<p><strong>copytruncate 模式</strong>： </p>\n<ol>\n<li>copy 当前日志文件，重命名为新的日志文件，这样进程还是往老的日志文件写入。</li>\n<li>对老的日志文件进行 truncate 清空，这样就完成了一次日志切割。</li>\n</ol>\n</li>\n<li>\n<p><strong>sign 通知模式</strong>： </p>\n<ol>\n<li>首先重命名当前进程正在输出的日志文件名称。因为日志文件是用 inode 来在磁盘上标识，更改日志文件名称并不会影响 inode 号，进程依旧会往修改了名称的日志文件内输出日志。</li>\n<li>创建新的日志文件，文件名称和老的日志文件名称保持一致。因为是新建的文件，inode 号不一样。此时进程日志还是依旧输出到老的被重命名了的日志文件里面。</li>\n<li>对进程发起信号通知，让其重载日志的配置文件，实现平滑重启，后续的日志就会写入到新建的日志文件里。</li>\n</ol>\n</li>\n</ul>\n<p>日志切割组件一般都支持可配置日志切割频率，也有两种方式：</p>\n<ul>\n<li>定时切割： 进程启动一个定时任务，到设定时间后切割日志文件。</li>\n<li>按大小切割：进程定时监控日志文件的大小，若文件超出设定的最大值时进行切割。</li>\n</ul>\n<h3>Node.js 应用日志切割</h3>\n<p>对于前端 Node.js 应用来说，根据项目的框架和部署架构，可选择不同的日志切割方案，例如：</p>\n<ul>\n<li>基于 pm2 部署的 Node.js 应用，可采用 <code class=\"language-text\">pm2-logrotate</code> 实现日志切割。</li>\n<li>基于 Egg.js 框架的 Node.js 应用，可采用 <code class=\"language-text\">egg-logrotator</code> 实现日志切割。</li>\n</ul>\n<p>下面我们详细介绍一下这两种日志切割方案的实现原理。</p>\n<h2>pm2-logrotate</h2>\n<h3>实现机制</h3>\n<p><code class=\"language-text\">pm2-logrotate</code>  是 pm2 扩展的日志管理插件，适用于 pm2 部署的 Node.js 应用，同时支持定时切割和按大小切割。</p>\n<p>可通过如下的命令来设置一些配置参数：</p>\n<div class=\"gatsby-highlight\" data-language=\"javascript\"><pre class=\"language-javascript\"><code class=\"language-javascript\">pm2 <span class=\"token keyword\">set</span> pm2<span class=\"token operator\">-</span>logrotate<span class=\"token punctuation\">:</span><span class=\"token operator\">&lt;</span>param<span class=\"token operator\">></span> <span class=\"token operator\">&lt;</span>value<span class=\"token operator\">></span></code></pre></div>\n<p>其中的关键配置项如下：</p>\n<ul>\n<li>\n<p><strong>max_size</strong></p>\n<p>日志文件的最大体积，默认值为 10 * 1024 * 1024</p>\n</li>\n<li>\n<p><strong>retain</strong></p>\n<p>切割出的日志文件最大份数，默认值为 30</p>\n</li>\n<li>\n<p><strong>dateFormat</strong></p>\n<p>日期格式，基于该日期名生成切割出的日志文件名称，默认值为 YYYY-MM-DD_HH-mm-ss</p>\n</li>\n<li>\n<p><strong>workerInterval</strong></p>\n<p>按大小切割时，文件扫描的间隔时间（s），默认值为 30</p>\n</li>\n<li>\n<p><strong>rotateInterval</strong></p>\n<p>定时切割的时间间隔（支持<a href=\"http://unixhelp.ed.ac.uk/CGI/man-cgi?crontab+5\">cron表达式</a>），默认值为 0 0 * * *</p>\n</li>\n</ul>\n<p>对于<code class=\"language-text\">pm2-logrotate</code>  本身的实现机制，我们探究源码总结出了一些关键的步骤，具体如图所示：</p>\n<p><img src=\"https://p1.music.126.net/p1zE-2k7ieN6z_1xokaTMg==/109951164831066057.jpg\" alt=\"pm2-logrotate\"></p>\n<p>其中切割机制的核心源码如下，从这里我们可以看出 <code class=\"language-text\">pm2-logrotate</code> 采用了上文介绍的 <strong>copytruncate 模式</strong>。</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre class=\"language-js\"><code class=\"language-js\"><span class=\"token comment\">// 日志切割的具体过程</span>\n<span class=\"token keyword\">function</span> <span class=\"token function\">proceed</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">file</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token comment\">// 设置时间作为新的日志文件名</span>\n  <span class=\"token keyword\">var</span> final_time <span class=\"token operator\">=</span> <span class=\"token function\">moment</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">format</span><span class=\"token punctuation\">(</span><span class=\"token constant\">DATE_FORMAT</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">var</span> final_name <span class=\"token operator\">=</span> file<span class=\"token punctuation\">.</span><span class=\"token function\">substr</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> file<span class=\"token punctuation\">.</span>length <span class=\"token operator\">-</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token string\">'__'</span> <span class=\"token operator\">+</span> final_time <span class=\"token operator\">+</span> <span class=\"token string\">'.log'</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token comment\">// 创建 read/write streams，将日志写入到新的日志文件中</span>\n  <span class=\"token keyword\">var</span> readStream <span class=\"token operator\">=</span> fs<span class=\"token punctuation\">.</span><span class=\"token function\">createReadStream</span><span class=\"token punctuation\">(</span>file<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">var</span> writeStream <span class=\"token operator\">=</span> fs<span class=\"token punctuation\">.</span><span class=\"token function\">createWriteStream</span><span class=\"token punctuation\">(</span>final_name<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'flags'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'w+'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> \n    \n  readStream<span class=\"token punctuation\">.</span><span class=\"token function\">pipe</span><span class=\"token punctuation\">(</span>writeStream<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  \n  <span class=\"token comment\">// 日志写入完毕后， 清空应用的日志文件</span>\n  writeStream<span class=\"token punctuation\">.</span><span class=\"token function\">on</span><span class=\"token punctuation\">(</span><span class=\"token string\">'finish'</span><span class=\"token punctuation\">,</span> <span class=\"token keyword\">function</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    readStream<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    writeStream<span class=\"token punctuation\">.</span><span class=\"token function\">close</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    fs<span class=\"token punctuation\">.</span><span class=\"token function\">truncate</span><span class=\"token punctuation\">(</span>file<span class=\"token punctuation\">,</span> <span class=\"token keyword\">function</span> <span class=\"token punctuation\">(</span><span class=\"token parameter\">err</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n      console<span class=\"token punctuation\">.</span><span class=\"token function\">log</span><span class=\"token punctuation\">(</span><span class=\"token string\">'\"'</span> <span class=\"token operator\">+</span> final_name <span class=\"token operator\">+</span> <span class=\"token string\">'\" has been created'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n      <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">typeof</span><span class=\"token punctuation\">(</span><span class=\"token constant\">RETAIN</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">===</span> <span class=\"token string\">'number'</span><span class=\"token punctuation\">)</span> \n        <span class=\"token function\">delete_old</span><span class=\"token punctuation\">(</span>file<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h3>IO 异常问题分析</h3>\n<p>重新回到本文开头的线上问题，由于我们的 Node.js 应用是基于 pm2 实现进程管理，同样也是基于 <code class=\"language-text\">pm2-logrotate</code> 来实现日志切割。</p>\n<p>在排查异常的时候，我们发现了 <code class=\"language-text\">pm2-logrotate</code> 在实现上的两个问题。</p>\n<h4>cluster 模式下重复切割日志的问题</h4>\n<p>通过追溯源码，我们可以确定  <code class=\"language-text\">pm2-logrotate</code>  会对所有由 pm2 启动的应用进行日志切割。</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre class=\"language-js\"><code class=\"language-js\">pm2<span class=\"token punctuation\">.</span><span class=\"token function\">list</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">function</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">err<span class=\"token punctuation\">,</span> apps</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  apps<span class=\"token punctuation\">.</span><span class=\"token function\">forEach</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">function</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">app</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token function\">proceed_app</span><span class=\"token punctuation\">(</span>app<span class=\"token punctuation\">,</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>但是，在 cluster 模式下，pm2 会启动多个相同的 woker 实例，而日志只会打印到同一份文件中。<strong>因此，当触发日志切割的条件时，多个 woker 实例会同时对日志文件进行切割，造成 IO 读写繁忙。</strong></p>\n<p><strong>同时， copytruncate 模式在日志切割的时候会拷贝原来的日志文件，也会造成系统磁盘使用空间突增。</strong></p>\n<p><strong>这个问题在日志文件体积大的时候尤为明显，也是我们 Node.js 应用线上 IO 异常的主因。</strong></p>\n<p>为了解决 cluster 模式下重复切割日志的问题，需要对多个 worker 实例进行去重判断，只允许一个实例进行日志切割的操作。具体的判断逻辑可分成两步：</p>\n<ul>\n<li>判断该实例是否为 cluster 模式下的实例。pm2 给每个应用实例提供了环境变量 pm2<em>env 来查看运行的状态。 `app.pm2</em>env.instances > 1` 则表明有多个相同的实例，可判定为 cluster 模式。</li>\n<li>判断是否有实例已经做了日志切割。多个 worker 实例的共同点是 <code class=\"language-text\">app.name</code> 应用名相同。因此，每次日志切割的时候新建一个 map 映射表，key 为 <code class=\"language-text\">app.name</code> ， 只有当映射表中没有查询到 <code class=\"language-text\">app.name</code> 的时候，才会进行日志切割。</li>\n</ul>\n<p>代码部分大致如下所示：</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre class=\"language-js\"><code class=\"language-js\">pm2<span class=\"token punctuation\">.</span><span class=\"token function\">list</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">function</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">err<span class=\"token punctuation\">,</span> apps</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token operator\">...</span>\n  <span class=\"token keyword\">var</span> appMap <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span>\n  apps<span class=\"token punctuation\">.</span><span class=\"token function\">forEach</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">function</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">app</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token comment\">// cluster模式下的去重判断</span>\n    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>app<span class=\"token punctuation\">.</span>pm2_env<span class=\"token punctuation\">.</span>instances <span class=\"token operator\">></span> <span class=\"token number\">1</span> <span class=\"token operator\">&amp;&amp;</span> appMap<span class=\"token punctuation\">[</span>app<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">return</span><span class=\"token punctuation\">;</span>\n    appMap<span class=\"token punctuation\">[</span>app<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> app<span class=\"token punctuation\">;</span>\n    \n\t\t<span class=\"token comment\">// 开始日志切割</span>\n    <span class=\"token function\">proceed_app</span><span class=\"token punctuation\">(</span>app<span class=\"token punctuation\">,</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>以上去重判断的逻辑已经提交 <a href=\"https://github.com/keymetrics/pm2-logrotate/pull/129\">PR</a> 并被 merged 。该问题已在 <code class=\"language-text\">pm2-logrotate</code> v2.7.0 的版本修复。</p>\n<h4>日志丢失问题</h4>\n<p><code class=\"language-text\">pm2-logrotate</code> 进行日志切割时，新的日志文件名是根据 <code class=\"language-text\">dateFormat</code> 参数格式化生成的，源码如下所示：</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre class=\"language-js\"><code class=\"language-js\"><span class=\"token keyword\">var</span> <span class=\"token constant\">DATE_FORMAT</span> <span class=\"token operator\">=</span> conf<span class=\"token punctuation\">.</span>dateFormat <span class=\"token operator\">||</span> <span class=\"token string\">'YYYY-MM-DD_HH-mm-ss'</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">var</span> final_time <span class=\"token operator\">=</span> <span class=\"token function\">moment</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">format</span><span class=\"token punctuation\">(</span><span class=\"token constant\">DATE_FORMAT</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">var</span> final_name <span class=\"token operator\">=</span> file<span class=\"token punctuation\">.</span><span class=\"token function\">substr</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> file<span class=\"token punctuation\">.</span>length <span class=\"token operator\">-</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token string\">'__'</span> <span class=\"token operator\">+</span> final_time <span class=\"token operator\">+</span> <span class=\"token string\">'.log'</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>该参数的默认值 <code class=\"language-text\">YYYY-MM-DD_HH-mm-ss</code>，可以精确到秒级别。在实际生产环境，为了便于检索和查看日志，文件的命名往往会按照按天/小时的维度进行命名。</p>\n<p>但是如果 <code class=\"language-text\">DATE_FORMAT</code> 的格式为 <code class=\"language-text\">YYYY-MM-DD</code> ，会存在这么一个坑：当一天中应用日志体积多次超出设置的 <code class=\"language-text\">max_size</code> 后，会出现多次切割的操作，但是每次切割生成的新日志文件名却是相同的。</p>\n<p><strong>在已有切割日志的情况下， <code class=\"language-text\">pm2-logrotate</code> 再次切割时不会判断新的日志文件是否已经存在，而是直接用新切割出来的日志覆盖了之前的日志，从而会导致日志丢失。</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre class=\"language-js\"><code class=\"language-js\"><span class=\"token comment\">// 如果final_name对应的文件不存在则创建，存在则整体内容覆盖</span>\n<span class=\"token keyword\">var</span> writeStream <span class=\"token operator\">=</span> fs<span class=\"token punctuation\">.</span><span class=\"token function\">createWriteStream</span><span class=\"token punctuation\">(</span>final_name<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'flags'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'w+'</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>  </code></pre></div>\n<p>针对该问题的解决方案，一方面可以通过设置 <code class=\"language-text\">dateFormat</code> 精确到秒级来避免；另一方面，需要评估日志文件的大小，合理设置 <code class=\"language-text\">max_size</code> 参数，避免频繁触发日志切割。</p>\n<h2>egg-logrotator</h2>\n<h3>实现机制</h3>\n<p><code class=\"language-text\">egg-logrotator</code>  是 Egg.js 框架扩展的日志切割插件。相较于 <code class=\"language-text\">pm2-logrotate</code> ， 其配置更加灵活，同时支持按天切割、按小时切割和按大小切割。关键配置项如下：</p>\n<ul>\n<li>\n<p><strong>filesRotateByHour</strong></p>\n<p>需要按小时切割的文件列表，默认值为 [ ]</p>\n</li>\n<li>\n<p><strong>hourDelimiter</strong></p>\n<p>按小时切割的文件，小时部分的分隔符号，默认值为 '-'</p>\n</li>\n<li>\n<p><strong>filesRotateBySize</strong></p>\n<p>需要按大小切割的文件列表，默认值为 [ ]</p>\n</li>\n<li>\n<p><strong>maxFileSize</strong></p>\n<p>日志文件的最大体积，默认值为 50 * 1024 * 1024</p>\n</li>\n<li>\n<p><strong>maxFiles</strong></p>\n<p>按大小切割时，文件最大切割的份数，默认值为 10</p>\n</li>\n<li>\n<p><strong>rotateDuration</strong></p>\n<p>按大小切割时，文件扫描的间隔时间， 默认值为 60000</p>\n</li>\n<li>\n<p><strong>maxDays</strong></p>\n<p>日志保留的最久天数，默认值为 31</p>\n</li>\n</ul>\n<p>具体切割的实现原理如图所示：</p>\n<p><img src=\"https://p1.music.126.net/1CITqfEtSuB74L78kCJCog==/109951164831643667.jpg\"></p>\n<p>其中的核心源码如下，相较于 <code class=\"language-text\">pm2-logrotate</code> ，从这里我们可以看出 <code class=\"language-text\">egg-logrotator</code> 则采用了另外一种 <strong>sign 通知模式</strong>。</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre class=\"language-js\"><code class=\"language-js\"><span class=\"token comment\">// rotate 日志切割源码</span>\n<span class=\"token keyword\">async</span> <span class=\"token function\">rotate</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  \t<span class=\"token comment\">// 获取需要切割的日志文件列表</span>\n    <span class=\"token keyword\">const</span> files <span class=\"token operator\">=</span> <span class=\"token keyword\">await</span> <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span><span class=\"token function\">getRotateFiles</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">const</span> rotatedFile <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">const</span> file <span class=\"token keyword\">of</span> files<span class=\"token punctuation\">.</span><span class=\"token function\">values</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token keyword\">try</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token comment\">// 重命名日志文件</span>\n        <span class=\"token keyword\">await</span> <span class=\"token function\">renameOrDelete</span><span class=\"token punctuation\">(</span>file<span class=\"token punctuation\">.</span>srcPath<span class=\"token punctuation\">,</span> file<span class=\"token punctuation\">.</span>targetPath<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        rotatedFile<span class=\"token punctuation\">.</span><span class=\"token function\">push</span><span class=\"token punctuation\">(</span><span class=\"token template-string\"><span class=\"token template-punctuation string\">`</span><span class=\"token interpolation\"><span class=\"token interpolation-punctuation punctuation\">${</span>file<span class=\"token punctuation\">.</span>srcPath<span class=\"token interpolation-punctuation punctuation\">}</span></span><span class=\"token string\"> -> </span><span class=\"token interpolation\"><span class=\"token interpolation-punctuation punctuation\">${</span>file<span class=\"token punctuation\">.</span>targetPath<span class=\"token interpolation-punctuation punctuation\">}</span></span><span class=\"token template-punctuation string\">`</span></span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n      <span class=\"token punctuation\">}</span> <span class=\"token keyword\">catch</span> <span class=\"token punctuation\">(</span>err<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>rotatedFile<span class=\"token punctuation\">.</span>length<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n      <span class=\"token comment\">// reload 重新加载日志文件</span>\n      <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>logger<span class=\"token punctuation\">.</span><span class=\"token function\">info</span><span class=\"token punctuation\">(</span><span class=\"token string\">'[egg-logrotator] broadcast log-reload'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n      <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>messenger<span class=\"token punctuation\">.</span><span class=\"token function\">sendToApp</span><span class=\"token punctuation\">(</span><span class=\"token string\">'log-reload'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n      <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>app<span class=\"token punctuation\">.</span>messenger<span class=\"token punctuation\">.</span><span class=\"token function\">sendToAgent</span><span class=\"token punctuation\">(</span><span class=\"token string\">'log-reload'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\n<span class=\"token comment\">// reload重新加载日志文件</span>\n<span class=\"token function\">reload</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span><span class=\"token function\">_closeStream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>   <span class=\"token comment\">// 结束当前日志文件流</span>\n  <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>_stream <span class=\"token operator\">=</span> <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span><span class=\"token function\">_createStream</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">// 创建一个新的写日志文件流</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h3>优势</h3>\n<p>就实现方式而言，copytruncate 模式较简单，sign 通知模式则较为复杂，需要有一套完整的通知重启机制。</p>\n<p>但是相较于基于 copytruncate 模式实现的<code class=\"language-text\">pm2-logrotate</code>，基于 sign 通知模式实现的 <code class=\"language-text\">egg-logrotator</code> 具有两点明显的优势：</p>\n<ul>\n<li>copytruncate 模式在日志切割的过程中需要拷贝原来的日志文件，如果日志文件过大，系统可用空间会突然爆增。sign 通知模式则无需拷贝原来的日志文件。</li>\n<li>对于按大小切割的场景， <code class=\"language-text\">egg-logrotator</code> 充分考虑了切割出的日志文件命名问题。新的日志文件会被命名为  <code class=\"language-text\">${final_name}.1</code>。当已有切割文件时，会将原文件自增1，如文件名后缀加1（ <code class=\"language-text\">.log.1</code> -> <code class=\"language-text\">.log.2</code> ），直到日志文件数量达到 <code class=\"language-text\">maxFiles</code> 最大值后，才会直接覆盖最后一份 <code class=\"language-text\">.log.${maxFiles}</code>。这种实现方式能够最大程度上保证日志的完整性。</li>\n</ul>\n<h2>小结</h2>\n<p>日志切割是完善 Node.js 服务可观测性的重要前提，是实现日志可视化检索、日志监控告警和全链路日志分析的前置条件之一。</p>\n<p>本文对通用的日志切割原理进行了阐述，展开说明了 Node.js 应用中两种常用的日志切割方案及其背后的实现机制，并对两种实现方案进行了优劣对比。希望给大家在 Node.js 的生产实践中带来启示和帮助。</p>\n<h2>参考资料</h2>\n<ul>\n<li><a href=\"https://github.com/keymetrics/pm2-logrotate\">pm2-logrotate</a></li>\n<li><a href=\"https://github.com/eggjs/egg-logrotator\">egg-logrotator</a></li>\n<li><a href=\"http://www.lightxue.com/how-logrotate-works\">logrotate机制和原理</a></li>\n</ul>\n<blockquote>\n<p>本文发布自 <a href=\"https://github.com/x-orpheus\">网易云音乐前端团队</a>，文章未经授权禁止任何形式的转载。我们一直在招人，如果你恰好准备换工作，又恰好喜欢云音乐，那就 <a href=\"mailto:grp.music-fe@corp.netease.com\">加入我们</a>！</p>\n</blockquote>","frontmatter":{"title":"Node.js 应用日志切割原理与踩坑实践","date":"2020-05-09","description":"2019 年初的时候，我们业务组上线了一个新的 Node.js 应用，主要提供C端的 API 服务。 随着应用流量的逐渐增加，线上监控平台会偶发性报警，提示磁盘 disk_io 平均等待时间超出 1000ms，随后观察发现磁盘 IO 每秒写字节量突然飙高，但很快又下降。"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/node-log-rotate/","previous":{"fields":{"slug":"/node-cli/"},"frontmatter":{"title":"Node CLI 工具的插件方案探索"}},"next":{"fields":{"slug":"/react-hooks/"},"frontmatter":{"title":"React Hooks 最佳实践"}}}}}